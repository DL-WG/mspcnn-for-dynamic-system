{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we are going to show how to train your own MSPC-LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base of MSPC-LSTM is multiple layers AE/CAEs. To train the multiple layers CAEs, 4 datasets are required: high-fidelity training data, high-fidelity testing data, low-fidelity training data and low-fidelity testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_train_data_path = 'HF_train_data_path'\n",
    "HF_test_data_path = 'HF_test_data_path'\n",
    "LF_train_data_path = 'LF_train_data_path'\n",
    "LF_test_data_path = 'LF_test_data_path'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load data by customized dataloader.py to get specific dataloader.\n",
    "You can use the dataloader.py by \"from models import dataloader\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import dataloader\n",
    "# for high fidelity cae\n",
    "HF_CAE_train_loader = dataloader.load_data(HF_train_data_path,model='HighFidelityCAE', batch_size=20, shuffle=True)\n",
    "# for the test data, we can set test=True to get tensor rather than a dataloader\n",
    "HF_CAE_test_data = dataloader.load_data(HF_test_data_path, model='HighFidelityCAE', test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low-fidelity AE/CAEs should not only accept high-fidelity data but also low-fidelity data. We also set a specific way to generate dataloader for low-fidelity cae training.\n",
    "\n",
    "In function $\\text{dataloader.load\\_data}$, when the $\\text{model='LowFidelityCAE'}$, it can accept an extra parameter $\\text{low\\_fidelity\\_path}$ to get the low-fidelity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_CAE_train_loader = dataloader.load_data(HF_train_data_path, model='LowFidelityCAE', low_fidelity_path=LF_train_data_path, batch_size=20, shuffle=True)\n",
    "LF_test_data, HF_test_data = dataloader.load_data(HF_test_data_path, model='LowFidelityCAE', low_fidelity_path=LF_test_data_path, batch_size=20, shuffle=True, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the multiple layers CAE, LSTM is another part of the MSPC-LSTM. In this model, LSTM is used to do Seq2Seq predcition. However, in order to reduce the memory requirements for model training, we first batch the data and then sequence it during the training process, so please set $\\text{model='LSTM'}$ in the dataloader generated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_train_loader = dataloader.load_data(HF_train_data_path, model='LSTM', batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the sequence length, we can set it in training function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize MSPC-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize a MSPC-LSTM, you need to prepare two AEs and one LSTM model first, which is customized for your data. There we put the example of shallow water model, whose shape of high-fidelity data is (3,64,64) and low-fidelity data is (3,32,32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure of two CAEs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=2, padding=1)  # output size: 32x32\n",
    "        self.conv2 = nn.Conv2d(32, 16, 3, stride=2, padding=1)  # output size: 16x16\n",
    "        self.dense = nn.Linear(16 * 16 * 16, 512)  # Added dense layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = self.dense(x) # F.relu(self.dense(x))  # Apply dense layer\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dense = nn.Linear(512, 16 * 16 * 16)  # Added dense layer\n",
    "        self.t_conv1 = nn.ConvTranspose2d(16, 32, 3, stride=2, padding=1, output_padding=1)  # output size: 32x32\n",
    "        self.t_conv2 = nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1)  # output size: 64x64\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense(x) # F.relu(self.dense(x))  # Apply dense layer\n",
    "        x = x.view(x.size(0), 16, 16, 16)  # Reshape the input\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        x = self.t_conv2(x)  # No activation here\n",
    "        return x\n",
    "\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "class low_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(low_Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=2, padding=1)  # output size: 16x16\n",
    "        self.conv2 = nn.Conv2d(16, 16, 3, stride=2, padding=1)  # output size: 8x8\n",
    "        self.dense = nn.Linear(16 * 8 * 8, 512)  # Added dense layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = self.dense(x) # F.relu(self.dense(x))  # Apply dense layer\n",
    "        return x\n",
    "\n",
    "class low_Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(low_Decoder, self).__init__()\n",
    "        self.dense = nn.Linear(512, 16 * 8 * 8)  # Added dense layer\n",
    "        self.t_conv1 = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1, output_padding=1)  # output size: 16x16\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1)  # output size: 32x32\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense(x) # F.relu(self.dense(x))  # Apply dense layer\n",
    "        x = x.view(x.size(0), 16, 8, 8)  # Reshape the input\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        x = self.t_conv2(x)  # No activation here\n",
    "        return x\n",
    "    \n",
    "class low_CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE, self).__init__()\n",
    "        self.encoder = low_Encoder()\n",
    "        self.decoder = low_Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure of LSTM\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out)  # we only want the last 3 time steps\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After constructing the structure of the models, you can initialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_CAE = CAE()\n",
    "LF_CAE = low_CAE()\n",
    "LSTM = Seq2Seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can initialize the MSPC-LSTM directly or set a subclass of MSPC-LSTM class as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import model\n",
    "# initialize MSPC-LSTM directly\n",
    "MSPC_LSTM = model.MSPC_LSTM(HF_CAE, LF_CAE, LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you initialize the MPSC-LSTM model directly, we have equipped the class with basic training fucntion of high-fidelity cae, low-fidelity cae and lstm. You can call them by $\\text{train\\_HFCAE, train\\_LFCAE, train\\_LSTM}$. After training, you can use function $\\text{predict}$ to get prediction.\n",
    "\n",
    "However, if you want to embed your own physical constraints into the model, you need to initialize a subclass of MSPC-LSTM, and add the specific physical-constraint functions and LSTM training precess. There is the example of shallow water problem embedded with energy conservation and flow operator physical constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SW_MSPC_LSTM(model.MSPC_LSTM):\n",
    "    \n",
    "    def __init__(self, HF_CAE, LF_CAE, LSTM, device=None):\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        self.HF_CAE = HF_CAE.to(self.device)\n",
    "        self.LF_CAE = LF_CAE.to(self.device)\n",
    "        self.LSTM = LSTM.to(self.device)\n",
    "        self.HF_encoder = self.HF_CAE.encoder\n",
    "        self.HF_decoder = self.HF_CAE.decoder\n",
    "        self.LF_encoder = self.LF_CAE[0]\n",
    "        self.LF_decoder = self.LF_CAE[1]\n",
    "\n",
    "    def train_LSTM_with_PC(self, train_loader, test_data, energy_coef=None, fo_coef=None, decoder_type=None, batch_size=20, num_epochs=30, lr=0.0001, criterion_type='mse'):\n",
    "        # Coerce coefficients to lists if they are not\n",
    "        if isinstance(energy_coef, (int, float)):\n",
    "            energy_coef = [energy_coef] * num_epochs\n",
    "        if isinstance(pde_coef, (int, float)):\n",
    "            pde_coef = [pde_coef] * num_epochs\n",
    "        # Load loss function\n",
    "        criterion = load_loss_function(criterion_type)\n",
    "\n",
    "        # Optimizers for the LSTM\n",
    "        optimizer = torch.optim.Adam(self.LSTM.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "\n",
    "        # Set test dataset\n",
    "        b, s, c, w, h = test_data.shape\n",
    "        test_compr = self.HF_encoder(test_data.view(-1, c, w, h))\n",
    "        test_dataset = dataloader.load_data(test_compr.reshape(b,s,-1), model='Seq2Seq', lookback=3, lookahead=3)\n",
    "\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_epoch_loss, test_epoch_loss = 0., 0.\n",
    "\n",
    "            # Training\n",
    "            self.LSTM.train()\n",
    "            for i, train_batch in enumerate(train_loader):\n",
    "                b, s, c, h, w = train_batch.shape\n",
    "                train_compr = self.HF_encoder(train_batch.view(-1, c, w, h))\n",
    "                train_compr_dataset = dataloader.load_data(train_compr.reshape(b, s, -1).cpu().detach().numpy(), model='seq2seq', lookback=3, lookahead=3)\n",
    "                for j in range(train_compr_dataset.__len__()):\n",
    "                    inputs, targets = train_compr_dataset[j]\n",
    "                    inputs = torch.tensor(inputs).to(self.device)\n",
    "                    targets = torch.tensor(targets).to(self.device)\n",
    "\n",
    "                    outputs = self.LSTM(inputs)\n",
    "\n",
    "                    mse_loss = criterion(outputs, targets)\n",
    "                    total_loss = mse_loss\n",
    "                    if energy_coef is not None:\n",
    "                        energy_loss = torch.abs(torch.mean((self.calculate_total_energy(inputs, decoder_type) -  #, dx=0.02\n",
    "                                                    torch.mean(self.calculate_total_energy(outputs, decoder_type), dim=1, keepdim=True)))) # , dx=0.02\n",
    "                        total_loss += energy_coef[epoch]*energy_loss\n",
    "                    if fo_coef is not None:\n",
    "                        fo_loss = self.compute_evolve_loss(inputs, outputs, decoder_type)\n",
    "                        total_loss += fo_coef[epoch]*fo_loss\n",
    "\n",
    "                    train_epoch_loss += total_loss.item()/len(train_loader)/len(train_compr_dataset)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    total_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # Testing\n",
    "            self.LSTM.eval()\n",
    "            with torch.no_grad():\n",
    "                for j in range(test_dataset.__len__()):\n",
    "                    test_inputs, test_targets = test_dataset[j]\n",
    "                    test_inputs = test_inputs.to(self.device)\n",
    "                    test_targets = test_targets.to(self.device)\n",
    "\n",
    "                    test_outputs = self.LSTM(test_inputs)\n",
    "\n",
    "                    test_mse_loss = criterion(test_outputs, test_targets)\n",
    "                    test_total_loss = test_mse_loss\n",
    "\n",
    "                    if energy_coef is not None:\n",
    "                        test_energy_loss = torch.abs(torch.mean((self.calculate_total_energy(test_inputs, decoder_type) -  #, dx=0.02\n",
    "                                                    torch.mean(self.calculate_total_energy(test_outputs, decoder_type), dim=1, keepdim=True)))) # , dx=0.02\n",
    "                        test_total_loss += energy_coef[epoch]*test_energy_loss\n",
    "                    if fo_coef is not None:\n",
    "                        test_fo_loss = self.compute_evolve_loss(test_inputs, test_outputs, decoder_type)\n",
    "                        test_total_loss += fo_coef[epoch]*test_fo_loss\n",
    "\n",
    "                    test_epoch_loss += test_total_loss.item()/len(test_data)\n",
    "\n",
    "            # Print the averaged loss per epoch\n",
    "            print ('Epoch [{}/{}], MSE_Loss: {:.6f}, Total_Loss: {:.6f}, Test_MSE_Loss: {:.6f}, Test_Total_Loss: {:.6f}'\n",
    "                .format(epoch+1, num_epochs, mse_loss.item(), train_epoch_loss, test_mse_loss.item(), test_epoch_loss))\n",
    "\n",
    "            train_losses.append(train_epoch_loss)\n",
    "            test_losses.append(test_epoch_loss)\n",
    "\n",
    "    def calculate_total_energy(self, data_compr, decoder_type):\n",
    "        # Set decoder for physcial constraints\n",
    "        if decoder_type == 'high':\n",
    "            decoder = self.HF_decoder\n",
    "            dx = 0.01\n",
    "        else:\n",
    "            decoder = self.LF_decoder\n",
    "            dx = 0.02\n",
    "\n",
    "        g = 9.8\n",
    "\n",
    "        N, Nt, latent = data_compr.shape\n",
    "        energies = torch.zeros(N, Nt)\n",
    "        # reconstruct the data\n",
    "        data = decoder(data_compr.reshape(N*Nt, latent))\n",
    "        data = data.reshape(N, Nt, *data.shape[-3:])\n",
    "        for i in range(N):\n",
    "            for j in range(Nt):\n",
    "                # Calculate kinetic energy\n",
    "                kinetic_energy = 0.5 * (torch.sum(data[i][j][0]**2) + torch.sum(data[i][j][1]**2)) * dx**2\n",
    "\n",
    "                # Calculate potential energy\n",
    "                potential_energy = torch.sum(0.5 * g * data[i][j][2]**2) * dx**2\n",
    "\n",
    "                # Calculate total energy\n",
    "                energies[i, j] = kinetic_energy + potential_energy\n",
    "\n",
    "        return energies\n",
    "    \n",
    "    def dxy(self, A, dx, axis=0):\n",
    "        return (roll(A, -1, axis) - roll(A, 1, axis)) / (dx*2.)\n",
    "\n",
    "    def d_dx(self, A, dx):\n",
    "        return self.dxy(A, dx, 2)\n",
    "\n",
    "    def d_dy(self, A, dx):\n",
    "        return self.dxy(A, dx, 1)\n",
    "\n",
    "    def d_dt(self, h, u, v, dx):\n",
    "        for x in [h, u, v]:\n",
    "            assert isinstance(x, ndarray) and not isinstance(x, matrix)\n",
    "        g, b = 1., 0.2\n",
    "        du_dt = -g*self.d_dx(h, dx) - b*u\n",
    "        dv_dt = -g*self.d_dy(h, dx) - b*v\n",
    "        H = 0 \n",
    "        dh_dt = -self.d_dx(u * (H+h), dx) - self.d_dy(v * (H+h), dx)\n",
    "        return dh_dt, du_dt, dv_dt\n",
    "    \n",
    "    def evolve(self, h, u, v, dt=0.0001, dx=0.01):\n",
    "        dh_dt, du_dt, dv_dt = self.d_dt(h, u, v, dx)\n",
    "        h += dh_dt * dt\n",
    "        u += du_dt * dt\n",
    "        v += dv_dt * dt\n",
    "        return h, u, v\n",
    "\n",
    "    def compute_evolve_loss(self, input_data_compr, outputdata_compr, decoder_type, dt=0.0001):\n",
    "        if decoder_type == 'high':\n",
    "            decoder = self.HF_decoder\n",
    "            dx = 0.01\n",
    "        else:\n",
    "            decoder = self.LF_decoder\n",
    "            dx = 0.02\n",
    "\n",
    "        N, Nt_in, latent = input_data_compr.shape\n",
    "        N, Nt_out, latent = input_data_compr.shape\n",
    "        input_images = decoder(input_data_compr.reshape(N*Nt_in, latent))\n",
    "        input_images = input_images.reshape(N, Nt_in, *input_images.shape[-3:])\n",
    "        output_images = decoder(outputdata_compr.reshape(N*Nt_out, latent))\n",
    "        output_images = output_images.reshape(N, Nt_out, *output_images.shape[-3:])\n",
    "        u = input_images[:,-1,0,:].cpu().detach().numpy()\n",
    "        v = input_images[:,-1,1,:].cpu().detach().numpy()\n",
    "        h = input_images[:,-1,2,:].cpu().detach().numpy()\n",
    "        output_images_evolved = torch.empty((N, Nt_out, *output_images.shape[-3:]))\n",
    "        for i in range(Nt_out):\n",
    "            h, u, v = self.evolve(h, u, v, dt, dx)\n",
    "            output_image_evolved = torch.stack((torch.tensor(u), torch.tensor(v), torch.tensor(h)), dim=1)\n",
    "            output_images_evolved[:, i, :, :, :] = output_image_evolved\n",
    "        output_images_evolved = output_images_evolved.to(self.device)\n",
    "        # calculate the asymmetry\n",
    "        FO_loss = nn.MSELoss()(output_images_evolved, output_images)\n",
    "        return FO_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_MSPC_LSTM = SW_MSPC_LSTM(HF_CAE, LF_CAE,LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clarify, the CAEs training processes is general, so there is no need to overwrite it again in subclass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have prepared the dataset and the model, now we are going to train the model.\n",
    "\n",
    "The first step is training the high-fidelity CAE by function $\\text{train\\_HFCAE}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_MSPC_LSTM.train_HFCAE(HF_CAE_train_loader, HF_test_data, num_epochs=30, lr=0.0001, criterion_type='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low-fidelity CAE can be trained after the high-fidelity CAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_MSPC_LSTM.train_LFCAE(LF_CAE_train_loader, LF_test_data, HF_test_data, num_epochs=30, lr=0.0001, criterion_type='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the multiple layers CAEs, we can train the LSTM now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_MSPC_LSTM.train_LSTM_with_PC(HF_CAE_train_loader, HF_test_data, energy_coef=0.0001, fo_coef=0.0001, decoder_type='low', batch_size=20, num_epochs=30,lr=0.0001, criterion_type='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the $\\text{decoder\\_type}$ means that what decoder you want to apply on the physcial constraints. The defalut decoder is low-fidelity deocoder, you can set $\\text{decoder\\_type = 'high'}$ to apply high-fidelity decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the MSPC-LSTM model is all trained, and you can use the predict function to make predictions. At the same time, if you have trained CAEs and LSTMs, you can also directly pass them in without going through the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For specific call predictions and accompanying plot usage, see the specific prediction sample file: 'Burgers'_equation.ipynb' and 'Shallow_Water.ipynb'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
